{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10-using CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXGXUX319CkJHzAWze4mae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedaMeem/cifar10/blob/main/CIFAR10_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyGKXpb8eIRZ"
      },
      "source": [
        "CIFAR10->airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck.\n",
        "They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images\n",
        "\n",
        "The CIFAR-100 dataset ->\n",
        "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "\n",
        "Here is the list of some classes in the CIFAR-100:\n",
        "\n",
        "Superclass ->        Classes\n",
        "[aquatic mammals\t->   beaver, dolphin, otter, seal, whale].\n",
        "[fish ->\t             aquarium fish, flatfish, ray, shark, trout].\n",
        "[flowers\t->           orchids, poppies, roses, sunflowers, tulips]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mglIS2j9RdIf"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzjMjDZneqLF"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,regularizers\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXEPZbsLetp6",
        "outputId": "f2d461ec-3afd-4cfb-e551-3416adf4a275"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhRq2cjImY9R"
      },
      "source": [
        "(50000,32,32,3)->(no. of images,each image width,each image height,rgb color model-3 channnel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZos3GEmzxR"
      },
      "source": [
        "#converting float64->float32 to minimize computation\n",
        "#divide by 255 gray level value to normalize all pixels values between 0 to 1\n",
        "\n",
        "x_train=x_train.astype(\"float32\")/255.0\n",
        "x_test=x_test.astype(\"float32\")/255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq62PQjoIEuP"
      },
      "source": [
        "#Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ0blcpZ1PzR",
        "outputId": "882d3e83-1703-4676-f483-a85f85b267ef"
      },
      "source": [
        "##Convolutional Network\n",
        "\n",
        "#padding='valid' -> the output of the layer according to kernel operation i.e. may be 30*30. it is set by default,so need not to mention it explicitly.\n",
        "#padding='same' -> the output of the layer according to prvious layer i.e. input layer 32*32. it is not set by default,so need to mention it explicitly.\n",
        "\n",
        "model=keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape=(32,32,3)),\n",
        "     layers.Conv2D(32,(3,3),padding='valid',activation='relu'),\n",
        "     layers.MaxPooling2D(pool_size=(2,2)),\n",
        "     layers.Conv2D(64,(3,3),padding='valid',activation='relu'),\n",
        "     layers.MaxPooling2D(pool_size=(2,2)),\n",
        "     layers.Conv2D(128,(3,3),padding='valid',activation='relu'),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64,activation='relu'),\n",
        "     layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                131136    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T21QrwKl1Q9o"
      },
      "source": [
        "##Training  network configuration\n",
        "# from_logits=True ->it's going to send the softmax function to the output layer of the network \n",
        "#and then it's going to map it to sparse categorical cross entropy\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yyeQnNs1Riw",
        "outputId": "11947d8d-3030-4aeb-c908-bd48110b4a6b"
      },
      "source": [
        "#More of the concrete training of that network\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2)\n",
        "model.evaluate(x_test,y_test,batch_size=64,verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 60s - loss: 1.7128 - accuracy: 0.3765\n",
            "Epoch 2/10\n",
            "782/782 - 59s - loss: 1.3492 - accuracy: 0.5207\n",
            "Epoch 3/10\n",
            "782/782 - 59s - loss: 1.2193 - accuracy: 0.5695\n",
            "Epoch 4/10\n",
            "782/782 - 59s - loss: 1.1258 - accuracy: 0.6069\n",
            "Epoch 5/10\n",
            "782/782 - 59s - loss: 1.0510 - accuracy: 0.6350\n",
            "Epoch 6/10\n",
            "782/782 - 60s - loss: 0.9837 - accuracy: 0.6582\n",
            "Epoch 7/10\n",
            "782/782 - 60s - loss: 0.9332 - accuracy: 0.6760\n",
            "Epoch 8/10\n",
            "782/782 - 59s - loss: 0.8834 - accuracy: 0.6965\n",
            "Epoch 9/10\n",
            "782/782 - 60s - loss: 0.8433 - accuracy: 0.7075\n",
            "Epoch 10/10\n",
            "782/782 - 60s - loss: 0.8027 - accuracy: 0.7230\n",
            "157/157 - 3s - loss: 0.8892 - accuracy: 0.6952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8892107605934143, 0.6952000260353088]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LRQfoFjMOQJ"
      },
      "source": [
        "#Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0MCbT21SL6"
      },
      "source": [
        "##Convolutional Network\n",
        "\n",
        "def my_model():\n",
        "  inputs = keras.Input(shape=(32,32,3))\n",
        "  x=layers.Conv2D(32,3)(inputs)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.MaxPooling2D()(x)\n",
        "  x=layers.Conv2D(64,5,padding='same')(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Conv2D(128,3,padding='valid')(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Flatten()(x)\n",
        "  x=layers.Dense(64,activation='relu')(x)\n",
        "  outputs=layers.Dense(10)(x)\n",
        "  model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model=my_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkFI1omPzrXy"
      },
      "source": [
        "##Convolutional Network with regularizer and dropout\n",
        "\n",
        "def my_model():\n",
        "  inputs = keras.Input(shape=(32,32,3))\n",
        "  x=layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(0.01),)(inputs)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.MaxPooling2D()(x)\n",
        "  x=layers.Conv2D(64,5,padding='same',kernel_regularizer=regularizers.l2(0.01),)(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Conv2D(128,3,padding='same',kernel_regularizer=regularizers.l2(0.01),)(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Flatten()(x)\n",
        "  x=layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01),)(x)\n",
        "  x=layers.Dropout(0.5)(x)\n",
        "  outputs=layers.Dense(10)(x)\n",
        "  model=keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model=my_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAq2zUfH1S7r"
      },
      "source": [
        "##Training  network configuration\n",
        "# from_logits=True ->it's going to send the softmax function to the output layer of the network \n",
        "#and then it's going to map it to sparse categorical cross entropy\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btLQtFasQKWT",
        "outputId": "86b24fd6-7246-4e9d-9db1-c3aa173c4151"
      },
      "source": [
        "#More of the concrete training of that network\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2)\n",
        "model.evaluate(x_test,y_test,batch_size=64,verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 264s - loss: 1.2842 - accuracy: 0.5453\n",
            "Epoch 2/10\n",
            "782/782 - 254s - loss: 0.8795 - accuracy: 0.6926\n",
            "Epoch 3/10\n",
            "782/782 - 266s - loss: 0.7235 - accuracy: 0.7459\n",
            "Epoch 4/10\n",
            "782/782 - 288s - loss: 0.6039 - accuracy: 0.7891\n",
            "Epoch 5/10\n",
            "782/782 - 277s - loss: 0.5154 - accuracy: 0.8202\n",
            "Epoch 6/10\n",
            "782/782 - 248s - loss: 0.4266 - accuracy: 0.8530\n",
            "Epoch 7/10\n",
            "782/782 - 252s - loss: 0.3557 - accuracy: 0.8777\n",
            "Epoch 8/10\n",
            "782/782 - 247s - loss: 0.2954 - accuracy: 0.8989\n",
            "Epoch 9/10\n",
            "782/782 - 245s - loss: 0.2343 - accuracy: 0.9218\n",
            "Epoch 10/10\n",
            "782/782 - 245s - loss: 0.1903 - accuracy: 0.9373\n",
            "157/157 - 12s - loss: 1.0825 - accuracy: 0.7021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0824909210205078, 0.7020999789237976]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}